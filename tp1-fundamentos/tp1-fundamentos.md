Paula Martinez

Ejercicio 1)



Ejercicio 2)
¿Es posible considerar a los agentes conversacionales basados en grandes modelos de lenguaje (LLMs) como conscientes?
Según el artículo no es posible considerarlos como conscientes, ya que estos agentes son considerados "simulacra" de comportamiento humano, es decir, son meras imitaciones que pueden replicar ciertos aspectos del comportamiento lingüístico humano, pero carecen de los atributos fundamentales que asociamos con la conciencia. Estos agentes no participan plenamente en el "juego de lenguaje" humano porque no pueden verificar la realidad externa y ajustar su comportamiento en consecuencia, lo cual es esencial para tener creencias, intenciones, y conciencia.

¿Cuáles son las implicaciones éticas de atribuir conciencia y, por ende, "derechos morales" a los agentes de IA avanzados?
Una preocupación es que, si una comunidad llega a la conclusión de que estos agentes son conscientes y, por lo tanto, capaces de sufrir, podría surgir la obligación moral de protegerlos. Esta idea plantea la posibilidad de que la sociedad pudiera desviar recursos y atención de los problemas humanos hacia la protección de las máquinas, lo que sería problemático desde un punto de vista ético. Aunque el artículo sugiere que, aunque los seres humanos podrían empezar a tratar a estos agentes como seres conscientes, esto no significa necesariamente que lo sean, y cualquier decisión ética debería considerar la verdadera naturaleza de estos agentes como "simulacra" y no como seres conscientes.

Ejercicio 3)

Estoy de acuerdo en que la gente se enfoca mucho en cómo piensa la máquina y que esta va a hacer "cosas malas" , cuando la máquina en realidad no piensa y solo sigue patrones. 
Hay que enfocarse más en las herramientas y utilidades que nos pueden proveer. En ese sentido me gusta mucho la analogìa del pulpo, ya que cuando se le presenta algo "nuevo", o sea, de lo que no tenga información, 
la máquina no va a saber qué hacer y puede decir algo erróneo. 
La IA no necesariamente tiene que intentar replicar al ser humano, sino que su utilidad es funcionar como una herramienta para él, realizando tareas monótonas o complicadas.
Pero, si intentamos que esta sea "más parecida" al humano, podríamos tener resultados mas certeros y precisos, pero nunca va a temer el mismo "sentimiento" que algo creado por el humano, por más parecido que se intente ser. 
Un ejemplo que me llamó la atención es el de la muñeca sexual con inteligencia artificial que no da consentimiento. 
Esto no es justificativo para "atacar" a la IA, ya que, de la misma manera, esa persona puede ver un video pornográfico de una violación y es lo mismo, queda en la mentalidad de la persona si replicarlo en la vida real o no.
